{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal: Customer Data Migration Analysis using Pandas\n",
    "* In this solution, I use a Python script to upload data to Google's Cloud Platform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  First assumption: We are migrating to Cloud Firestore\n",
    "*  Second assumption: Firebase Admin SDK has been installed with Python\n",
    "*  Third assumption: Service Key has been generated from the Firebase Project Console\n",
    "*  Fourth assumption: prior_call and prior_email_call are customers who have contacted the call center previously via calls and email\n",
    "*  Fifth assumption: gmail_email_i is the column which indicates if customers have been migrated or not. Where it is 0, means migration has not taken place and where it is 1, means migration has taken place."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import firebase_admin\n",
    "import google.cloud\n",
    "from firebase_admin import credentials, firestore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set credentials\n",
    "    * initialize Firestore server on system/localhost account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred = credentials.Certificate(\"accountkey.json\") # insert path to service account key generated from firestore here \n",
    "app = firebase_admin.initialize_app(cred) \n",
    "\n",
    "db = firestore.client() # initialize client\n",
    "\n",
    "file_path = \"CLEANED_CSV_FILE_PATH\"         # file path \n",
    "collection_name = \"COLLECTION_TO_ADD_TO\"    # Firestore table to migrate data into"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create function to create batch processing, cleaning function, reading csv and uploading to NoSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(iterable, n=1):\n",
    "    \"\"\" \n",
    "        create batch function to limit size of uploads\n",
    "    \"\"\"\n",
    "    for ndx in range(0, len(iterable), n):\n",
    "        yield iterable[ndx:min(ndx + n, len(iterable))]\n",
    "\n",
    "def clean_data(_csv):\n",
    "    \"\"\"  \n",
    "        read in the data and clean it.\n",
    "        create subset of data for customers who can be prioritized for immediate migration.\n",
    "        filter the data by setting a threshold value to filter out customers who have contacted the call centre more than once and are not yet migrated, based on fifth assumption.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(_csv)\n",
    "\n",
    "    if 'cust_id' in data.columns:\n",
    "        data = data.drop_duplicates(subset='cust_id', keep='first')\n",
    "\n",
    "    # create a new column by adding columns prior calls and emails - this gives a new column with the total number of contacts into the call centre\n",
    "    data['total_contact_mode'] = data['prior_call'] + data['prior_email_call']\n",
    "    data['total_contact_mode'].sort_values(ascending=False)\n",
    "\n",
    "    # create a new column by adding columns prior calls and emails - this gives a new column with the total number of contacts into the call centre\n",
    "    data['total_contact_mode'] = data['prior_call'] + data['prior_email_call']\n",
    "    cleaned_data = data[(data['total_contact_mode'] >= 1) & (data['gmail_email_i'] == 0)]\n",
    "\n",
    "    return cleaned_data.to_csv('cleaned_data.csv', index=False)\n",
    "\n",
    "data = []\n",
    "headers = []\n",
    "with open(file_path) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            for header in row:\n",
    "                headers.append(header)\n",
    "            line_count += 1\n",
    "        else:\n",
    "            obj = {}\n",
    "            for idx, item in enumerate(row):\n",
    "                obj[headers[idx]] = item\n",
    "            data.append(obj)\n",
    "            line_count += 1\n",
    "    print(f'Processed {line_count} lines.')\n",
    "\n",
    "\"\"\"\n",
    "    Loop through data and add data to the Firestore NoSQL database in batches of 500 - Firestore batch uploading limit\n",
    "\"\"\"\n",
    "for batched_data in batch_data(data, 499):\n",
    "    batch = db.batch()\n",
    "    for data_item in batched_data:\n",
    "        doc_ref = db.collection(collection_name).document()\n",
    "        batch.set(doc_ref, data_item)\n",
    "    batch.commit()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In conclusion, from the five assumptions, non-Gmail customers who have repeatedly called into the centre several times above the set threshold would give a fraction of customers who can be migrated in batches of 500."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
